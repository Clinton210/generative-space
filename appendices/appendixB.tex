\chapter{Dependency Bounds and Finite Prefix Principles}
\label{appendix:dependency-bounds}

\section{Introduction}

This appendix presents the technical background for dependency bounds,
prefix stabilization, and finite prefix analysis used throughout
Parts II and III. These ideas originate in Type 2 computability and
represented space theory as developed by Weihrauch and Pauly.
They explain why continuous observers examine only finite portions
of a generative identity and why tail regions can be modified freely
once the observer requirements have been met.

The results in this appendix support structural projections,
observer families, alignment methods, and the diagonalizer
construction. They should be read together with Appendix~A,
which treats effective closed sets and Pi zero one classes.

\section{Continuous Maps on Product Spaces}

Let $X$ be a product of discrete alphabets equipped with the product
topology and basic cylinders determined by finite prefixes. The ambient
generative space used in the main text is of this form.

A function
\[
\Phi : X \to \mathbb{R}
\]
is continuous exactly when its value at any point can be approximated
to any chosen precision using only a finite initial prefix.

\begin{lemma}
\label{lem:basic-continuity}
Let $\Phi : X \to \mathbb{R}$ be continuous. For every
$\varepsilon > 0$ there exists $N \in \mathbb{N}$ such that
\[
G[0..N] = H[0..N]
\quad \Longrightarrow \quad
|\Phi(G) - \Phi(H)| < \varepsilon.
\]
\end{lemma}

\begin{proof}
Continuity at each point implies the existence of a basic open
neighborhood on which $\Phi$ varies by less than $\varepsilon$.
Since cylinder sets form a basis of the topology, one may take
a finite prefix defining such a neighborhood and use its length
as $N$.
\end{proof}

The integer $N$ witnessing Lemma~\ref{lem:basic-continuity} is the
finite amount of symbolic information needed to evaluate the map at
precision $\varepsilon$.

\section{Dependency Bounds}

\begin{definition}
\label{def:dependency-bound}
A dependency bound for a continuous map
$\Phi : X \to \mathbb{R}$ is a function
$B_{\Phi} : (0,1] \to \mathbb{N}$ such that
\[
G[0..B_{\Phi}(\varepsilon)]
=
H[0..B_{\Phi}(\varepsilon)]
\quad \Longrightarrow \quad
|\Phi(G) - \Phi(H)| < \varepsilon
\]
for all $\varepsilon$ in $(0,1]$.
\end{definition}

Dependency bounds quantify the finite information principle.  
Every observer can see only a finite portion of a generative identity
at a chosen scale. This is the source of prefix stabilization
and controlled tail manipulation used in the main text.

When $\Phi$ is computable in the sense of represented space theory,
a computable bound exists. See Appendix~A for the general framework.

\begin{lemma}
\label{lem:computable-bound}
If $\Phi$ is computable, then it admits a computable
dependency bound.
\end{lemma}

\begin{proof}
A Type 2 machine computing $\Phi$ examines only finitely many input
symbols in order to produce an approximation to precision $\varepsilon$.
The number of inspected symbols provides a computable choice of
$B_{\Phi}(\varepsilon)$.
\end{proof}

\section{Uniform Dependency Bounds}

Many arguments require simultaneous control of several observers.

\begin{definition}
\label{def:uniform-bound}
Let $\mathcal{P} = \{\Phi_1, \ldots, \Phi_k\}$ be a finite family of
continuous maps $X \to \mathbb{R}$.
A uniform dependency bound is a function
$B_{\mathcal{P}} : (0,1] \to \mathbb{N}$ such that
\[
G[0..B_{\mathcal{P}}(\varepsilon)]
=
H[0..B_{\mathcal{P}}(\varepsilon)]
\quad \Longrightarrow \quad
|\Phi_i(G) - \Phi_i(H)| < \varepsilon
\]
for all $i$.
\end{definition}

\begin{lemma}
\label{lem:uniform-bound}
A uniform dependency bound exists for every finite family
$\mathcal{P}$, and one may take
\[
B_{\mathcal{P}}(\varepsilon)
=
\max_{1 \le i \le k} B_{\Phi_i}(\varepsilon).
\]
\end{lemma}

\begin{proof}
If the first $B_{\Phi_i}(\varepsilon)$ coordinates of $G$ and $H$
coincide, then $\Phi_i(G)$ and $\Phi_i(H)$ differ by less than
$\varepsilon$. Taking the maximum ensures that all such conditions
hold simultaneously.
\end{proof}

Uniform bounds play a central role in freezing observer families
during alignment and sewing, as used in the construction of the
diagonalizer in Chapter~\ref{chap:incompleteness}.

\section{Prefix Stabilization}

The finite prefix behavior encoded by dependency bounds implies that
observers become insensitive to all symbolic information beyond their
dependency horizon.

\begin{proposition}
\label{prop:prefix-stabilization}
Let $\Phi$ be continuous and let $N = B_{\Phi}(\varepsilon)$.
If $G$ and $H$ agree on $[0..N]$, then
\[
|\Phi(G) - \Phi(H)| < \varepsilon.
\]
\end{proposition}

\begin{proof}
This is immediate from the definition of a dependency bound and
Lemma~\ref{lem:basic-continuity}.
\end{proof}

Prefix stabilization is used repeatedly when controlling observers at
finite stages while allowing full freedom in the tail.

\section{Tail Stability Under Modification}

Once the dependency bound has been satisfied, the remainder of the
identity can be altered without changing the observer output beyond the
chosen precision.

\begin{proposition}
\label{prop:tail-stability}
Let $\Phi$ be continuous, let $\varepsilon > 0$, and let
$N = B_{\Phi}(\varepsilon)$. If $\widetilde{G}$ is obtained from $G$ by
replacing all coordinates strictly beyond index $N$ with any other tail,
then
\[
|\Phi(\widetilde{G}) - \Phi(G)| < \varepsilon.
\]
\end{proposition}

\begin{proof}
By construction, $\widetilde{G}$ and $G$ agree on $[0..N]$.
The result follows from Proposition~\ref{prop:prefix-stabilization}.
\end{proof}

This fact is the key engine behind controlled tail divergence:
beyond the observer horizon, identities can be modified freely.
Appendix~D applies this principle in the sewing method.

\section{Observer Families and Synchronization}

In the main text, observer towers appear as computable sequences
\[
\Phi_0, \Phi_1, \Phi_2, \ldots
\]
each with a dependency bound. The construction of the diagonalizer relies
on the ability to choose prefix lengths that satisfy these bounds for each
observer in turn.

\begin{lemma}
\label{lem:observer-sync}
Let $(\Phi_k)$ be a computable sequence of observers with computable
dependency bounds $B_k$. For each $k$ and each $\varepsilon_k$ in
$(0,1]$ one can compute an index $N_k$ such that for all $j \le k$,
\[
N_k \ge B_j(\varepsilon_j).
\]
\end{lemma}

\begin{proof}
Since the sequence of bounds is computable, the finite maximum
\[
\max_{j \le k} B_j(\varepsilon_j)
\]
is computable. Set $N_k$ equal to this maximum.
\end{proof}

This synchronization lemma is used in Appendix~C to build the
prefix alignment tools and in Appendix~D to construct the sewing
procedure.

\section{Summary}

Dependency bounds formalize the finite information principle that
underlies the behavior of all continuous observers. Each observer is
limited to a finite prefix at any chosen precision, and families of
observers admit uniform bounds. These tools yield prefix stabilization,
tail stability, and observer synchronization. They are indispensable in:

\begin{itemize}
    \item the alignment and sewing constructions,
    \item the effective generative freedom arguments,
    \item the structural incompleteness theorem,
    \item the analysis of derived invariants.
\end{itemize}

Together, these principles provide the computational and topological
foundation for the observer layer of the generative identity framework.
